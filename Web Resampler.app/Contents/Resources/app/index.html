<!DOCTYPE html>
<html>
    <head>
        <title>Web Resampler</title>
        <link href="css/skeleton.css" rel="stylesheet">
    </head>
    <body>
		<div class="container" style="width: 600px;">
			<h1 style="text-align: center">Web Resampler</h1>
            <div class="container">
                <button class="u-full-width button-primary" onclick="getElementById('fileInput').click()">Upload a file.</button>
                <i>Target sample rate.</i>
                <br>
                <select id="sampleRate">
                    <option value=22050>22050</option>
                    <option value=24000>24000</option>
                    <option value=44100>44100</option>
                    <option value=48000>48000</option>
                    <option value=88200>88200</option>
                    <option value=96000>96000</option>
                </select>
            </div>
            <div style="height: 375px; overflow: scroll;">
                <p>
                    A simple application that resamples an uploaded .wav file and downloads the result. Upsampling is achieved by simple linear interpolation, the equation used can be found <a href="https://www.easycalculation.com/formulas/linear-interpolation.html">here</a>. My javascript implementation is below.
                </p>
                <pre>
                    <code>
function linearInterpolate(x1, y1, x2, y2, targetX) {
    var targetY;
    targetY = ((targetX - x1) * (y2 - y1) / (x2 - x1)) + y1;
    return targetY;
}
                    </code>
                </pre>
                <p>
                    The targetX value comes from calculating <code>inputSR / outputSR</code> and incrementing this value after every interpolation calculation. If <code>targetX</code> exceeds <code>i + 1</code> we then increment <code>i</code> to move on to interpolating between the next two values in the array.
                </p>
                <pre>
                    <code>
while (i &lt; inputLength) {
    audioOutputLeft[j] = linearInterpolate(i, inL[i], i + 1, inL[i + 1], targetX);
    audioOutputRight[j] = linearInterpolate(i, inR[i], i + 1, inR[i + 1], targetX);
    j += 1;
    targetX += count;
    if (targetX &gt;= i + 1) {
        i += 1;
    }
}
                    </code>
                </pre>
                <p>
                    Downsampling is accomplished by taking every n samples from the input where n is the downsampling ratio; <code>inputSR / outputSR</code>. When this value is not an integer first the input signal is upsampled to the lowest multiple of the desired samplerate that is greater than the input samplerate. The audio is not filtered and aliasing <b><i>will</i></b> be present if the source audio contains frequencies above the nyquist frequency of the output sample rate.
                </p>
                <pre>
                    <code>
function downsample(inL, inR, targetSampleRate) {
    var i = 0,
        j = 0,
        downsamplingFactor = inputSampleRate / targetSampleRate,
        filterStateL = 0,
        filterStateR = 0,
        tempSampleRate;
    if (downsamplingFactor % 1 !== 0) {
        i = 0;
        while (i &lt; 10) {
            if (targetSampleRate * i > inputSampleRate) {
                tempSampleRate = targetSampleRate * i;
                break;
            } else {
                i += 1;
            }
        }
        upsample(inL, inR, tempSampleRate);
        inL = audioOutputLeft;
        inR = audioOutputRight;
        downsamplingFactor = tempSampleRate / targetSampleRate;
    }
    audioOutputLeft = new Float32Array(inputLength / downsamplingFactor);
    audioOutputRight = new Float32Array(inputLength / downsamplingFactor);
    for (i = 0; i &lt; inputLength; i += downsamplingFactor) {
        audioOutputLeft[j] = filterStateL + (inL[i] * 0.5);
        filterStateL = inL[i] * 0.25;
        audioOutputLeft[j] += filterStateL;
        audioOutputRight[j] = filterStateR + (inR[i] * 0.5);
        filterStateR = inR[i] * 0.25;
        audioOutputRight[j] += filterStateR;
        j += 1;
    }
}
                    </code>
                </pre>
                <p>
                    Information from the RIFF header is read and written according to the specification found <a href="http://soundfile.sapp.org/doc/WaveFormat/">here</a>. More specifically, the binary data is stored and written in an ArrayBuffer, a JavaScript object representing raw binary data. An ArrayBuffer cannot be manipulated directly, instead a DataView is created which can read the data at any given byte as the type specifed. For example <code>DataView.getUint16(32, true)</code> will read that data at byte 32 as an unsigned 16bit integer. The <code>true</code> argument is optional and if specified reads the data as little endian.
                </p>
                <pre>
                    <code>
audioInfoDataView = new DataView(this.result);
console.log('Input information:');
inputNumChannels = audioInfoDataView.getUint16(22, true);
console.log('Channel count: ' + inputNumChannels);
inputSampleRate = audioInfoDataView.getUint32(24, true);
console.log('Sample rate: ' + inputSampleRate);
inputBitDepth = audioInfoDataView.getUint16(34, true);
console.log('Bit depth: ' + inputBitDepth);
inputLength = audioInfoDataView.getUint32(40, true) / inputNumChannels / (inputBitDepth / 8);
console.log('Audio length (samples): ' + inputLength);
console.log('Audio length (seconds): ' + inputLength / inputSampleRate);
                    </code>
                </pre>
            </div>
        </div>
        <input id="fileInput" type="file" accept=".wav" style="display:none;">
        <script src="js/resampler.js" type="text/javascript"></script>
    </body>
</html>